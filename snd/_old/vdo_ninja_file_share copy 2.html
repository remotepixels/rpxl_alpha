<!doctype html>
<html lang="en">

<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>VDO.Ninja P2P File Share</title>
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Roboto:ital,wght@0,100..900;1,100..900&display=swap"
    rel="stylesheet">
  <link href="https://fonts.googleapis.com/css2?family=Material+Symbols+Outlined:wght@200" rel="stylesheet">
  <link rel="stylesheet" href="style.css">
</head>

<body>
  <div id="mainWindow" class="mainWindow">
    <!--top menu bar-->
    <div id="topmenu" class="toolbar top">
      <div class="toolset">
        <button class="tool" id="shareBtn" aria-expanded="false" role="button">
          <span class="material-symbols-outlined">ios_share</span>
        </button>
      </div>
      <div class="toolset">
        <span class="tool toolwider">Status : <span id="senderStatus">Idle</span></span>
        <span class="tool toolwider">Peers : <span id="peersList">(0)</span></span>
      </div>
      <div class="toolset">
        <button class="tool toolmoresettings" id="logBtn" aria-expanded="false" role="button">
          <span class="material-symbols-outlined">terminal</span></button>
      </div>
    </div>
    <div class="logAndFiles">
      <pre class="log hidden" id="log"></pre>
      <div class="file-list" id="fileList"></div>
      <div class="copyCredit">Powered by vdo.ninja</div>
    </div>

  </div>

  <div id="container" style="display: none;"></div>

  <div class="drop" id="dropArea">
    <div class="material-symbols-outlined" style="cursor:pointer; font-size:256px;">drive_folder_upload</div>
    <div>
      <h1>Drag & drop files or folders here</h1>
    </div>
  </div>

  <!----- Copied links to clipboard ------>
  <div id="popupClipboard" class="toolpopup hidden">
    <div class="material-symbols-outlined" style="cursor:pointer; font-size:256px; color:rgba(180, 180, 180, 0.466);">
      assignment_turned_in</div>
    <div>
      <h1>Link copied to clipboard</h1>
    </div>
  </div>
</body>

</html>

<script lang="javascript">

  // Namespace used in messages sent through VDO.Ninja
  const APP_NS = 'p2pFileShareDemo';

  // ----------------------------------------
  let iframe = null;
  let connectedPeers = {}; // map streamID -> label
  let roomName = '';
  const files = {}; // id -> {file, name, size, chunks:[], progress}
  const folderMap = {}; // keeps track of folder DOM nodes
  const incomingGroups = {}; // { groupId: { files: {}, name: "folderName" } }

  const dropArea = document.getElementById('dropArea');
  const fileList = document.getElementById('fileList');
  const logEl = document.getElementById('log');
  const peersList = document.getElementById('peersList');
  const senderStatus = document.getElementById('senderStatus');

  const shareBtn = document.getElementById('shareBtn');
  const logBtn = document.getElementById('logBtn');

  const devURL = 'http://localhost:5500/transfer/vdo_ninja_file_share.html';

  //generate local uuID and store in localStorage
  let localUUID = localStorage.getItem('localUUID');
  if (!localUUID) {
    localUUID = crypto.randomUUID();
    localStorage.setItem('localUUID', localUUID);
  }
  console.log('Local Browser UUID:', localUUID);

  //log window
  function log(...args) {
    console.log(...args);
    logEl.textContent += args.join(' ') + '\n';
    logEl.scrollTop = logEl.scrollHeight;
  }

  shareBtn.addEventListener('click', () => {

    navigator.clipboard.writeText(`${devURL}?SID=${roomName}`);
    popupClipboard.classList.remove("hidden");
    setTimeout(() => {
      popupClipboard.classList.add("hidden");
    }, 2000);
    console.log('Session link copied to clipboard');
  });
  logBtn.addEventListener('click', () => {
    document.getElementById('log').classList.toggle('hidden');
  });
  checkSessionURL();  //autoconnect if session ID in URL

  //check if session ID is present in URL and autoconnect
  function checkSessionURL() {
    const queryURL = window.location.search.slice(1);
    let decodeURL;
    const params = new URLSearchParams(queryURL);
    if (params.has('SID')) {
      const SID = params.get('SID');
      const sanitizedSessionID = encodeURIComponent(SID);
      if (!sanitizedSessionID || sanitizedSessionID.length !== 20) {
        console.log('INCORRECTLY FORMATED SESSION ID');
        return;
      } else {
        console.log('SESSION ID FOUND IN URL:', sanitizedSessionID);
        createIframe(roomName)
        document.getElementById('shareBtn').classList.add('hidden');
        document.getElementById('dropArea').classList.add('hidden');
        return;
      }
    } else {
      var length = 20;
      const chars = 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789';
      roomName = Array.from({ length }, () => chars.charAt(Math.floor(Math.random() * chars.length))).join('');
      console.log('NO SESSION ID IN URL, GENERATING NEW ONE : ', roomName);
    }
  }

  // --- Join room / create iframe ---
  function createIframe(room) {
    if (iframe) iframe.remove();
    const container = document.getElementById('container');
    iframe = document.createElement('iframe');
    iframe.allow = 'camera;microphone;fullscreen;display-capture;autoplay;';

    iframe.src = `${devURL}?SID=${roomName}?director&room=${encodeURIComponent(room)}&dataonly&cleanish`;
    iframe.style.width = '100%';
    iframe.style.height = '180px';
    container.appendChild(iframe);

    // set up message listener
    const eventMethod = window.addEventListener ? 'addEventListener' : 'attachEvent';
    const eventer = window[eventMethod];
    const messageEvent = eventMethod === 'attachEvent' ? 'onmessage' : 'message';
    eventer(messageEvent, function (e) {
      if ('action' in e.data) handleAction(e.data);
      if ('dataReceived' in e.data) handleDataReceived(e.data.dataReceived, e.data.UUID);
      if ('streamIDs' in e.data) handleStreamIDs(e.data.streamIDs);
      if ('detailedState' in e.data) log('detailedState', e.data.detailedState);
    }, false);

    log('Joined room:', room);
  }

  window.addEventListener("message", function (e) {
    if ("dataReceived" in e.data) {
      console.log(e.data.dataReceived);
    }
  });

  function handleAction(data) {
    // see iframe docs: guest-connected, view-connection, push-connection, etc.
    if (data.action === 'guest-connected' && data.streamID) {
      connectedPeers[data.streamID] = data.value?.label || 'Guest';
      updatePeersUI();
      handleGuestJoin(data.streamID);
      log('Guest connected:', data.streamID, connectedPeers[data.streamID]);
    } else if (data.action === 'push-connection' && data.value === false && data.streamID) {
      log('Peer disconnected:', data.streamID);
      delete connectedPeers[data.streamID];
      updatePeersUI();
    } else if (data.action === 'view-connection') {
      if (data.value) { connectedPeers[data.streamID] = 'Viewer'; } else { delete connectedPeers[data.streamID]; }
      updatePeersUI();
      handleGuestJoin(data.streamID);
    }
  }

  async function handleGuestJoin(guestUUID) {
    log('Guest joined:', guestUUID);
    //delay to ensure peer connection is ready
    await sleep(500);

    const keys = Object.keys(files);
    if (keys.length > 0) {
      log(`Auto-sending ${keys.length} files to new guest ${guestUUID}...`);
      await sendAllFilesToPeer(guestUUID);
    } else {
      log('No files to send.');
    }
  }

  function handleStreamIDs(ids) {
    connectedPeers = ids; // object mapping streamID->label
    updatePeersUI();
  }

  function updatePeersUI() {
    const keys = Object.keys(connectedPeers);
    if (!keys.length) peersList.textContent = '(no peers yet)';
    else peersList.innerHTML = keys.map(k => `<div><strong>${connectedPeers[k]}</strong><div class="small">${k}</div></div>`).join('');
  }

  function requestPeerList() {
    if (!iframe) return log('Not connected');
    iframe.contentWindow.postMessage({ getStreamIDs: true }, '*');
  }

  //--- drag & drop / file handling ---
  dropArea.addEventListener('pointerdown', () => {
    const ip = document.createElement('input'); ip.type = 'file'; ip.multiple = true; ip.webkitdirectory = true;
    ip.addEventListener('change', (ev) => { handleFileList(ev.target.files); });
    ip.click();
  });

  const dropOverlay = document.getElementById('dropArea');
  let dragCounter = 0; // helps handle nested dragenter/dragleave events

  window.addEventListener('dragenter', (e) => {
    e.preventDefault();
    dragCounter++;
    dropOverlay.classList.add('dragover');
  });

  window.addEventListener('dragleave', (e) => {
    e.preventDefault();
    dragCounter--;
    if (dragCounter === 0) dropOverlay.classList.remove('dragover');
  });

  window.addEventListener('dragover', (e) => {
    e.preventDefault();
  });

  window.addEventListener('drop', (e) => {
    e.preventDefault();
    dragCounter = 0;
    dropOverlay.classList.remove('dragover');
  });

  dropArea.addEventListener('drop', async (e) => {
    const items = e.dataTransfer.items;
    if (!items) return handleFileList(e.dataTransfer.files);
    if (!iframe) {
      createIframe(roomName)
      log('Created room:', roomName);
    }
    document.getElementById('dropArea').classList.add('hidden');

    // Use directory traversal when available
    for (let i = 0; i < items.length; i++) {
      const it = items[i];
      const entry = it.webkitGetAsEntry && it.webkitGetAsEntry();
      if (entry && entry.isDirectory) {
        await readDirectory(entry);
      } else if (entry && entry.isFile) {
        entry.file(file => addFile(file));
      } else if (it.getAsFile) {
        addFile(it.getAsFile());
      }
    }
  });

  //filter hidden files
  function isHiddenFile(fileOrPath) {
    const name = typeof fileOrPath === 'string' ? fileOrPath : fileOrPath.name || '';
    return name.startsWith('.') || name === ''; // covers .DS_Store, .gitignore, etc.
  }

  // Recursive directory traversal
  async function readDirectory(dirEntry, path = '') {
    const reader = dirEntry.createReader();
    const readEntries = () => new Promise((res, rej) => reader.readEntries(res, rej));
    let entries = await readEntries();
    while (entries.length) {
      for (const e of entries) {
        if (e.isDirectory && !e.name.startsWith('.')) {
          await readDirectory(e, path + dirEntry.name + '/');
        } else if (e.isFile) {
          e.file((file) => {
            file.relativePath =
              (path ? path + dirEntry.name + '/' : dirEntry.name + '/') + file.name;
            if (!isHiddenFile(file)) addFile(file);
          });
        }
      }
      entries = await readEntries();
    }
  }

  // Called when user drops files/folders
  function handleFileList(list) {
    for (let i = 0; i < list.length; i++) {
      const file = list[i];
      if (!isHiddenFile(file)) addFile(file);
      else log(`Skipping hidden file: ${file.name}`);
    }
  }

  function addFile(file) {
    const id = generateId();
    const relativePath = file.relativePath || file.name;
    const pathParts = relativePath.split('/');
    const fileName = pathParts.pop();
    const folderPath = pathParts.join('/');

    files[id] = {
      id,
      file,
      name: fileName,
      size: file.size,
      folderPath,
      uploadedBy: localUUID,
      chunks: {},
      progress: 0,
      status: 'ready',
      startedAt: null,
      resumedAt: null
    };

    renderTreeItem(files[id]);
    log(`Added: ${relativePath} (${formatBytes(file.size)})`);

    // Notify peers
    //announceFile(id);
    sendFile(id, targetUUID);
  }

  //Build folder tree recursively
  function renderTreeItem(f) {
    const treeRoot = document.getElementById('fileList');
    const pathParts = f.folderPath ? f.folderPath.split('/') : [];
    let currentContainer = treeRoot;
    let currentPath = '';

    for (const part of pathParts) {
      currentPath = currentPath ? `${currentPath}/${part}` : part;

      // Skip if folder DOM already exists
      if (!folderMap[currentPath]) {
        const folderDiv = document.createElement('div');
        folderDiv.className = 'folder';
        folderDiv.dataset.path = currentPath;
        folderDiv.innerHTML = `
            <div class="folder-header" data-folder="${currentPath}">
              <span class="material-symbols-outlined folder-icon">folder</span>
              <strong class="folder-text">${escapeHtml(part)}</strong>
              <span class="material-symbols-outlined folder-delete">delete</span>
            </div>
            <div class="folder-contents"></div>
          `;
        currentContainer.appendChild(folderDiv);
        folderMap[currentPath] = folderDiv.querySelector('.folder-contents');

        // Folder toggle expand/collapse
        folderDiv.querySelector('.folder-header').addEventListener('click', (e) => {
          const contents = folderDiv.querySelector('.folder-contents');
          contents.style.display =
            contents.style.display === 'none' ? 'block' : 'none';
        });

        // Folder delete
        folderDiv.querySelector('.folder-delete').addEventListener('click', async (e) => {
          e.stopPropagation();
          const folderPath = e.target.closest('.folder-header').dataset.folder;
          if (confirm(`Delete entire directory "${folderPath}" and all its files?`)) {
            await deleteDirectory(folderPath);
          }
        });
      }
      currentContainer = folderMap[currentPath];
    }

    // Create file entry under its final folder
    const fileDiv = document.createElement('div');
    fileDiv.className = 'file-item';
    fileDiv.id = `data-${f.id}`;           // <--- important: id used by progress UI
    fileDiv.dataset.id = f.id;
    fileDiv.style.display = 'flex';
    fileDiv.style.justifyContent = 'space-between';
    fileDiv.style.alignItems = 'center';
    fileDiv.style.padding = '2px 10px';
    fileDiv.innerHTML = `
        <span class="file-name">${escapeHtml(f.name)}</span>
        <span class="small">${formatBytes(f.size)}</span>
        <span class="material-symbols-outlined file-delete">delete</span>
      `;
    currentContainer.appendChild(fileDiv);

    // Delete handler
    fileDiv.querySelector('.file-delete').addEventListener('click', async (e) => {
      e.stopPropagation();
      deleteFile(f.id);
    });
  }

  //delete files and folders
  async function deleteDirectory(path) {
    if (!path) return;
    log(`Deleting directory: ${path}`);

    // Find all file IDs inside that folder (recursively)
    const toDelete = Object.keys(files).filter(id =>
      files[id].folderPath.startsWith(path)
    );

    // Delete contained files
    for (const id of toDelete) {
      const el = document.querySelector(`.file-item[data-id="${id}"]`);
      if (el) el.remove();
      await sendFileRemoved(id);
      delete files[id];
    }

    // Remove the folder DOM
    const folderDiv = document.querySelector(`.folder[data-path="${path}"]`);
    if (folderDiv) folderDiv.remove();

    // Remove from folderMap
    delete folderMap[path];

    //announce directory removal to peers
    await sendDirectoryRemoved(path);

    //clean any now-empty parents
    cleanupEmptyFolders(path);
  }

  async function sendDirectoryRemoved(path, targetUUID = null) {
    const msg = {
      sendData: {
        [APP_NS]: {
          type: 'directory-removed',
          payload: { path, timestamp: Date.now() }
        }
      },
      type: 'pcs'
    };

    if (targetUUID) msg.to = targetUUID;

    postToIframe(msg);
    log(`Announced directory removal: ${path}${targetUUID ? ` → ${targetUUID}` : ''}`);
  }

  async function deleteFile(id) {
    const file = files[id];
    if (!file) return;

    const folderPath = file.folderPath || '';
    // Remove from files map
    delete files[id];

    // Remove from DOM
    const el = document.querySelector(`.file-item[data-id="${id}"]`);
    if (el) el.remove();

    log(`Deleted: ${file.name}`);

    // Clean up empty folders (locally)
    cleanupEmptyFolders(folderPath);
    // Send updated file list to peers
    await sendFileRemoved(id);
  }

  async function sendFileRemoved(id, targetUUID = null) {
    const msg = {
      sendData: {
        [APP_NS]: {
          type: 'file-removed',
          payload: { id, timestamp: Date.now() }
        }
      },
      type: 'pcs'
    };

    if (targetUUID) msg.to = targetUUID;

    postToIframe(msg);
    log(`Announced file removal: ${id}${targetUUID ? ` → ${targetUUID}` : ''}`);
  }

  //file sending
  async function sendAllFilesToPeer(targetUUID = null) {
    if (!iframe) return alert('Join a room first');
    const keys = Object.keys(files);
    if (!keys.length) return alert('No files');

    senderStatus.textContent = 'Sending...';
    for (const id of keys) {
      await sendFile(id, targetUUID);
    }
    senderStatus.textContent = 'All files queued';
  }

  // async function sendFile(id, targetUUID = null, resumeInfo = null) {
  //   const meta = files[id];
  //   if (!meta || !meta.file) {
  //     log(`sendFile(): missing file or meta for id=${id}`);
  //     return;
  //   }

  //   const file = meta.file;
  //   const totalChunks = Math.ceil(file.size / FILE_CHUNK_BYTES);
  //   const startChunk = resumeInfo?.nextChunk || 0;
  //   const sentChunks = new Set(resumeInfo?.sentChunks || []);
  //   const failedChunks = new Set();

  //   meta.startedAt = meta.startedAt || Date.now();
  //   meta.status = 'sending';
  //   createFileProgressUI(id, meta.name);

  //   // announce meta
  //   postToIframe({
  //     sendData: {
  //       [APP_NS]: {
  //         type: 'file-meta-announce',
  //         payload: { id, name: meta.name, size: meta.size, folderPath: meta.folderPath, totalChunks }
  //       }
  //     },
  //     type: 'pcs',
  //     to: targetUUID
  //   });

  //   // send each chunk sequentially with retry logic
  //   for (let i = startChunk; i < totalChunks; i++) {
  //     if (sentChunks.has(i)) continue; // resume skip
  //     const start = i * FILE_CHUNK_BYTES;
  //     const end = Math.min(file.size, start + FILE_CHUNK_BYTES);
  //     const slice = file.slice(start, end);
  //     try {
  //       const buffer = await readBlobAsArrayBuffer(slice);
  //       await sendChunkToPeer(targetUUID, id, i, totalChunks, buffer);
  //       sentChunks.add(i);

  //       // update progress + speed + ETA
  //       const percent = ((i + 1) / totalChunks) * 100;
  //       // const elapsed = (Date.now() - meta.startedAt) / 1000;
  //       // const bytesSent = (i + 1) * FILE_CHUNK_BYTES;
  //       // const speed = (bytesSent / 1024 / elapsed).toFixed(1);
  //       // const remaining = file.size - bytesSent;
  //       // const etaSec = remaining / (bytesSent / elapsed);
  //       //updateFileProgressUI(id, percent);

  //     } catch (err) {
  //       console.warn(`Chunk ${i} failed:`, err);
  //       failedChunks.add(i);
  //     }
  //     await sleep(CHUNK_SEND_DELAY);
  //   }

  //   // retry failed chunks once
  //   if (failedChunks.size > 0) {
  //     log(`Retrying ${failedChunks.size} failed chunks for ${meta.name}`);
  //     for (const i of [...failedChunks]) {
  //       try {
  //         const start = i * FILE_CHUNK_BYTES;
  //         const end = Math.min(file.size, start + FILE_CHUNK_BYTES);
  //         const slice = file.slice(start, end);
  //         const buffer = await readBlobAsArrayBuffer(slice);
  //         await sendChunkToPeer(targetUUID, id, i, totalChunks, buffer);
  //         failedChunks.delete(i);
  //       } catch (err) {
  //         console.error(`Retry failed for chunk ${i}:`, err);
  //       }
  //       await sleep(CHUNK_SEND_DELAY);
  //     }
  //   }

  //   // still missing chunks? Save resume info
  //   if (failedChunks.size > 0) {
  //     const resumeData = { id, nextChunk: Math.min(...failedChunks), sentChunks: [...sentChunks] };
  //     log(`Send incomplete for ${meta.name}, resumable at chunk ${resumeData.nextChunk}`);
  //     files[id].status = 'paused';
  //     files[id].resumeInfo = resumeData;
  //     return resumeData;
  //   }

  //   // ✅ All done
  //   postToIframe({
  //     sendData: { [APP_NS]: { type: 'file-transfer-complete', payload: { id, totalChunks } } },
  //     type: 'pcs',
  //     to: targetUUID
  //   });
  //   files[id].status = 'sent';
  //   log(`✅ File sent successfully: ${meta.name}`);
  // }

  // function resumeFileTransfer(id, targetUUID) {
  //   const meta = files[id];
  //   if (!meta?.resumeInfo) return log(`No resume data for ${id}`);
  //   log(`Resuming transfer for ${meta.name}`);
  //   sendFile(id, targetUUID, meta.resumeInfo);
  // }

  async function sendFile(id, targetUUID = null, resumeInfo = null) {
    const meta = files[id];
    if (!meta || !meta.file) {
      deleteFile(id)
      log(`sendFile(): missing file or meta for id=${id}`);
      return;
    }

    const fileMeta = {
      type: 'file-meta',
      id: id,
      name: meta.name,
      size: meta.size,
      folderPath: meta.folderPath || '',
      groupId: meta.groupId,
      uploadedBy: meta.uploadedBy,
      timestamp: Date.now()
    };

    const msg = {
      sendData: { [APP_NS]: { type: 'announce', payload: fileMeta } },
      type: 'pcs'
    };

    // If a specific peer UUID is given, send directly
    if (targetUUID) msg.to = targetUUID;

    postToIframe(msg);

    log(`Announced file meta: ${meta.name} (${meta.groupId})${targetUUID ? ` → ${targetUUID}` : ''}`);
  }

  // function announceFile(id, targetUUID = null) {
  //   const meta = files[id];
  //   if (!meta) return;

  //   postToIframe({
  //     sendData: {
  //       [APP_NS]: {
  //         type: 'file-meta-announce',
  //         payload: {
  //           id,
  //           name: meta.name,
  //           size: meta.size,
  //           folderPath: meta.folderPath,
  //           uploadedBy: meta.uploadedBy,
  //           totalChunks: Math.ceil(meta.size / FILE_CHUNK_BYTES)
  //         }
  //       }
  //     },
  //     type: 'pcs',
  //     to: targetUUID
  //   });
  // }

  //client side data receiving
  async function handleDataReceived(msg) {
    const data = msg[APP_NS];
    if (!data || !data.type) return;
    if (msg.data?.buffer) {
      console.log("Incoming transferable buffer:", msg.data.buffer.constructor.name, msg.data.buffer.byteLength);
    }
    switch (data.type) {
      case 'announce': {
        const f = data.payload;
        files[f.id] = {
          id: f.id,
          name: f.name,
          size: f.size,
          folderPath: f.folderPath || '',
          uploadedBy: msg.from || null
        };
        renderTreeItemReceiver(files[f.id]);
        log(`Received file meta: ${f.folderPath} / ${f.name} → ${targetUUID}`);
        break;
      }
      case 'file-removed': {
        const { id } = data.payload;
        const file = files[id];
        if (file) {
          const folderPath = file.folderPath || '';
          delete files[id];
          const el = document.querySelector(`.file-item[data-id="${id}"]`);
          if (el) el.remove();
          log(`File removed remotely: ${file.name}`);
          cleanupEmptyFolders(folderPath);
        }
        break;
      }
      case 'directory-removed': {
        const { path } = data.payload;
        log(`Directory removed remotely: ${path}`);
        // Remove folder DOM
        const folderDiv = document.querySelector(`.folder[data-path="${path}"]`);
        if (folderDiv) folderDiv.remove();
        // Clean folder map reference
        delete folderMap[path];
        // Remove any remaining files (if not already cleaned)
        for (const id of Object.keys(files)) {
          if (files[id].folderPath.startsWith(path)) {
            delete files[id];
            const el = document.querySelector(`.file-item[data-id="${id}"]`);
            if (el) el.remove();
          }
        }
        cleanupEmptyFolders(path);
        break;
      }
      case 'request-file': {
        // remote peer asks us to stream file to them
        const { id } = data.payload;
        const from = msg.from || null;
        respondToFileRequest(from, data.payload);
        break;
      }
      case 'file-meta-announce': {
        handleIncomingFileMeta(data.payload, msg.from || null);
        break;
      }
      case 'file-chunk': {
        await handleIncomingChunk(data.payload, msg);
        break;
      }
      case 'file-transfer-complete': {
        // finalize the file
        const { id } = data.payload;
        finalizeIncomingFile(id);
        break;
      }
      case 'file-not-found': {
        const { id } = data.payload;
        log(`Peer reports file not found: ${id}`);
        if (incomingFiles[id] && incomingFiles[id].reject) incomingFiles[id].reject(new Error('file-not-found'));
        break;
      }
      case 'file-transfer-error': {
        const { id, message } = data.payload;
        log(`Peer reported transfer error for ${id}:`, message);
        if (incomingFiles[id] && incomingFiles[id].reject) incomingFiles[id].reject(new Error(message || 'transfer-error'));
        break;
      }
      case 'chunk-ack': {
        const { id, index } = data.payload;
        if (outgoingFiles[id]) {
          outgoingFiles[id].acks = outgoingFiles[id].acks || {};
          outgoingFiles[id].acks[index] = true;
          // resolve waiting promise if present
          const key = `${id}:${index}`;
          const resolver = outgoingFiles[id].resolvers && outgoingFiles[id].resolvers[key];
          if (resolver) {
            try { resolver(); } catch (e) { }
            delete outgoingFiles[id].resolvers[key];
          }
        }
        break;
      }
      case 'request-missing': {
        // receiver asks for specific indices to be resent
        const { id, missing } = data.payload;
        log(`Peer requested missing chunks for ${id}:`, missing);
        if (!outgoingFiles[id]) {
          log('No outgoing state for', id);
          break;
        }
        const of = outgoingFiles[id];
        const file = of.meta?.file || files[id]?.file;
        if (!file) {
          log('Cannot resend missing - file not present');
          break;
        }
        // retransmit requested indices sequentially
        for (const idx of missing) {
          const start = idx * FILE_CHUNK_BYTES;
          const end = Math.min(file.size, start + FILE_CHUNK_BYTES);
          const blobSlice = file.slice(start, end);
          try {
            const buffer = await readBlobAsArrayBuffer(blobSlice);
            // send but do not necessarily await each ACK if you want faster behaviour
            await sendChunkWithRetry(of.to, id, idx, of.totalChunks, buffer);
          } catch (err) {
            log('Failed to resend chunk', idx, err);
          }
          await sleep(CHUNK_SEND_DELAY);
        }
        break;
      }
    }
  }

  // Remove any empty parent folders (recursively up)
  function cleanupEmptyFolders(startPath = null) {
    // climb up the tree from there and clean each ancestor if empty.
    if (startPath) {
      let parts = startPath.split('/');
      while (parts.length > 0) {
        const currentPath = parts.join('/');
        const folder = document.querySelector(`.folder[data-path="${currentPath}"]`);
        if (!folder) {
          parts.pop();
          continue;
        }

        const contents = folder.querySelector('.folder-contents');
        if (!contents || contents.children.length === 0) {
          log(`Removing empty folder: ${currentPath}`);
          folder.remove();
          delete folderMap[currentPath];
        }

        parts.pop(); // move up one level
      }
      return;
    }

    // If no path specified, do a full cleanup sweep
    const folders = document.querySelectorAll('.folder');
    for (const folder of folders) {
      const contents = folder.querySelector('.folder-contents');
      if (!contents || contents.children.length === 0) {
        const path = folder.dataset.path;
        log(`Removing empty folder: ${path}`);
        folder.remove();
        delete folderMap[path];
      }
    }
  }

  //client side tree rendering (download icons and actions instead of delete)
  function renderTreeItemReceiver(f) {
    const treeRoot = document.getElementById('fileList');
    const pathParts = f.folderPath ? f.folderPath.split('/') : [];
    let currentContainer = treeRoot;
    let currentPath = '';

    for (const part of pathParts) {
      currentPath = currentPath ? `${currentPath}/${part}` : part;

      if (!folderMap[currentPath]) {
        const folderDiv = document.createElement('div');
        folderDiv.className = 'folder';
        folderDiv.dataset.path = currentPath;
        folderDiv.innerHTML = `
            <div class="folder-header" data-folder="${currentPath}">
              <span class="material-symbols-outlined folder-icon">folder</span>
              <strong class="folder-text">${escapeHtml(part)}</strong>
              <span class="material-symbols-outlined folder-download">download</span>
            </div>
            <div class="folder-contents"></div>
      `;
        currentContainer.appendChild(folderDiv);
        folderMap[currentPath] = folderDiv.querySelector('.folder-contents');

        // Expand/collapse
        folderDiv.querySelector('.folder-header').addEventListener('click', (e) => {
          if (e.target.classList.contains('folder-download')) return;
          const contents = folderDiv.querySelector('.folder-contents');
          contents.style.display =
            contents.style.display === 'none' ? 'block' : 'none';
        });

        // Directory download request
        folderDiv.querySelector('.folder-download').addEventListener('click', (e) => {
          e.stopPropagation();
          const folderPath = e.target.closest('.folder-header').dataset.folder;
          requestDownload(folderPath, true); // true = folder
        });
      }

      currentContainer = folderMap[currentPath];
    }

    const fileDiv = document.createElement('div');
    fileDiv.className = 'file-item';
    fileDiv.id = `data-${f.id}`;           // <--- important: id used by progress UI
    fileDiv.dataset.id = f.id;
    fileDiv.style.display = 'flex';
    fileDiv.style.justifyContent = 'space-between';
    fileDiv.style.alignItems = 'center';
    fileDiv.style.padding = '3px 0';
    fileDiv.innerHTML = `
        <span class="file-name">${escapeHtml(f.name)}</span>
        <span class="small">${formatBytes(f.size)}</span>
        <span id=${f.id}_icon class="material-symbols-outlined file-download">download</span>
      `;
    currentContainer.appendChild(fileDiv);

    fileDiv.querySelector('.file-download').addEventListener('click', (e) => {
      e.stopPropagation();
      requestDownload(f.id, false); // false = single file
    });
  }

  // --- helpers: post message wrapper ---
  function postToIframe(msg, transferables = []) {
    if (!iframe || !iframe.contentWindow) return;
    try {
      iframe.contentWindow.postMessage(msg, "*", transferables);
    } catch (e) {
      console.error("postToIframe failed:", e);
    }
  }


  function handleFileMeta(meta) {
    const id = meta.id;
    if (!incomingFiles[id]) {
      incomingFiles[id] = { chunks: {}, totalChunks: meta.totalChunks, meta, receivedChunks: 0, size: meta.size, startedAt: Date.now() };
    }
    //createFileProgressUI(id, meta.name);
    log(`Preparing to receive file: ${meta.name}`);
  }

  function createFileProgressUI(id, name) {
    const item = document.getElementById(`${id}_icon`);
    if (!item) return;

    const progress = document.createElement('div');

    item.innerHTML = `
      <div class="roundProgressBarBG">
      <div class="roundProgressBarFill" id="progress-bar-${id}"></div>
          <div class="roundProgressBarCenter"></div>
      </div>`
  }

  function updateFileProgressUI(id, percent) {
    const bar = document.getElementById(`progress-bar-${id}`);
    const pct = Math.max(0, Math.min(100, Number(percent) || 0));
    const deg = pct * 3.6; // 100% -> 360°
    bar.style.backgroundImage = `conic-gradient(dodgerblue ${deg}deg, lightgrey ${deg}deg)`;
  }

  // // utility: read arrayBuffer from slice
  function sleep(ms) { return new Promise(r => setTimeout(r, ms)); }
  function generateId() { return Math.random().toString(36).slice(2, 10); }
  function formatBytes(a) { if (a === 0) return '0 B'; const units = ['B', 'KB', 'MB', 'GB', 'TB']; const e = Math.floor(Math.log(a) / Math.log(1024)); return (a / Math.pow(1024, e)).toFixed(2) + ' ' + units[e]; }
  function escapeHtml(s) { return String(s).replace(/[&<>\"']/g, c => ({ "&": "&amp;", "<": "&lt;", ">": "&gt;", "\"": "&quot;", "'": "&#39;" })[c]); }

  // ------------- Download + queue + chunking implementation -------------
  // Config
  const CHUNK_SIZE = 256 * 1024; // 256 KB Chunk size (bytes) for file transfer. Lower = more messages, smaller memory.
  const MAX_CONCURRENT_TRANSFERS = 5;    // browser concurrency limit
  const FILE_CHUNK_BYTES = CHUNK_SIZE;   // reuse CHUNK_SIZE you already have
  const CHUNK_SEND_DELAY = 10;           // ms between chunk sends to avoid congestion
  const CHUNK_ACK_TIMEOUT = 5000;    // ms to wait for an ack
  const CHUNK_MAX_RETRIES = 3;       // number of retries per chunk

  // Keep outgoing file send state: outgoingFiles[id] = { acks: {}, resolvers: {}, retries: {}, totalChunks, meta, paused }
  const outgoingFiles = {};

  // Queue state
  const downloadQueue = [];   // items: { id, fromUUID }
  let activeTransfers = 0;

  // Keep partial incoming file assembly
  // incomingFiles[id] = { chunks:[], totalChunks, receivedCount, meta: { name, size, folderPath, uploadedBy } }
  const incomingFiles = {};

  // Called by UI when user requests a download
  // idOrPath: either file id (for single file) or folder path (when isFolder true)
  async function requestDownload(idOrPath, isFolder = false) {
    if (!iframe) return alert('Join a room first');
    if (isFolder) {
      // enqueue all files under this folder
      const toDownload = Object.keys(files).filter(fid => files[fid].folderPath.startsWith(idOrPath));
      if (!toDownload.length) return alert('No files in directory');
      for (const fid of toDownload) enqueueDownload(fid);
      log(`Enqueued ${toDownload.length} files for folder download: ${idOrPath}`);
    } else {
      // single file id
      const fid = idOrPath;
      if (!files[fid]) return alert('File not found');
      enqueueDownload(fid);
      log(`Enqueued file: ${files[fid].name}`);
    }
    processDownloadQueue();
  }

  // add to queue
  function enqueueDownload(id, fromUUID = null) {
    downloadQueue.push({ id, fromUUID });
    files[id] = files[id] || {}; // ensure entry exists
    files[id].status = 'queued';
  }

  // main queue worker
  async function processDownloadQueue() {
    if (activeTransfers >= MAX_CONCURRENT_TRANSFERS) return;
    if (!downloadQueue.length) return;
    while (activeTransfers < MAX_CONCURRENT_TRANSFERS && downloadQueue.length) {
      const item = downloadQueue.shift();
      activeTransfers++;
      files[item.id].status = 'transferring';
      log(`Starting download: ${item.id} (${files[item.id].name || 'meta not present yet'})`);
      try {
        await requestFileFromPeer(item.id, item.fromUUID);
      } catch (err) {
        log('Download failed for', item.id, err);
        files[item.id].status = 'failed';
      } finally {
        activeTransfers--;
      }
    }
  }

  // ask peers for a file (will trigger peer-side responder)
  function requestFileFromPeer(id, targetUUID = null) {
    return new Promise((resolve, reject) => {
      const reqMsg = {
        sendData: {
          [APP_NS]: {
            type: 'request-file',
            payload: { id, timestamp: Date.now() }
          }
        },
        type: 'pcs'
      };
      if (targetUUID) reqMsg.to = targetUUID;

      // Setup a timeout in case no one responds
      let timedOut = false;
      const timeout = setTimeout(() => {
        timedOut = true;
        log(`Request timed out for file ${id}`);
        reject(new Error('request-timeout'));
      }, 30_000); // 30s timeout - adjust as necessary

      // Save callback to be invoked when file is fully received.
      // We'll use incomingFiles to track; check completion in handleDataReceived.
      incomingFiles[id] = incomingFiles[id] || { chunks: {}, totalChunks: null, receivedCount: 0, resolve, reject, meta: files[id] || {} };
      incomingFiles[id].resolve = () => {
        if (timedOut) return;
        clearTimeout(timeout);
        files[id].status = 'downloaded';
        log(`Download complete: ${id}`);
        resolve();
      };
      incomingFiles[id].reject = (err) => {
        if (timedOut) return;
        clearTimeout(timeout);
        files[id].status = 'failed';
        reject(err || new Error('receive-failed'));
      };

      postToIframe(reqMsg);
      log(`Requested file: ${id}${targetUUID ? ` → ${targetUUID}` : ''}`);
    });
  }

  // ---- Sender: respond to 'request-file' by streaming chunks ----
  async function respondToFileRequest(fromUUID, payload) {
    const { id } = payload;
    const meta = files[id];
    if (!meta || !meta.file) {
      // tell requester file not found
      postToIframe({
        sendData: { [APP_NS]: { type: 'file-not-found', payload: { id } } },
        type: 'pcs',
        to: fromUUID
      });
      log('Requested file not found locally:', id);
      return;
    }

    const file = meta.file;
    const totalChunks = Math.ceil(file.size / FILE_CHUNK_BYTES);
    log(`Streaming file ${meta.name} to ${fromUUID} in ${totalChunks} chunks`);

    // initialize outgoing state
    outgoingFiles[id] = outgoingFiles[id] || {
      acks: {},           // index -> true if acked
      resolvers: {},      // key -> resolve functions for ack waiting
      retries: {},        // index -> retry count
      totalChunks,
      meta,
      to: fromUUID,
      paused: false
    };

    // send initial meta so receiver knows total / filename
    postToIframe({
      sendData: { [APP_NS]: { type: 'file-meta-announce', payload: { id, name: meta.name, size: meta.size, folderPath: meta.folderPath || '', totalChunks } } },
      type: 'pcs',
      to: fromUUID
    });

    // send sequentially; you can also dispatch some in parallel for speed but ensure DataChannel isn't saturated
    for (let i = 0; i < totalChunks; i++) {
      if (!outgoingFiles[id] || outgoingFiles[id].paused) {
        log(`Send paused or cancelled for ${id} at chunk ${i}`);
        return;
      }

      const start = i * FILE_CHUNK_BYTES;
      const end = Math.min(file.size, start + FILE_CHUNK_BYTES);
      const blobSlice = file.slice(start, end);

      let buffer;
      try {
        buffer = await readBlobAsArrayBuffer(blobSlice);
      } catch (err) {
        log('Error reading chunk', i, err);
        postToIframe({
          sendData: { [APP_NS]: { type: 'file-transfer-error', payload: { id, message: err.message || 'chunk-read-error' } } },
          type: 'pcs',
          to: fromUUID
        });
        return;
      }

      try {
        await sendChunkWithRetry(fromUUID, id, i, totalChunks, buffer);
      } catch (err) {
        log(`Giving up on chunk ${i} for ${id}:`, err);
        // inform receiver that the transfer failed (so it can request-missing / abort)
        postToIframe({
          sendData: { [APP_NS]: { type: 'file-transfer-error', payload: { id, message: `chunk-failed-${i}` } } },
          type: 'pcs',
          to: fromUUID
        });
        return;
      }

      // small delay to avoid exhausting the datachannel
      await sleep(CHUNK_SEND_DELAY);
    }

    // finalise
    postToIframe({
      sendData: { [APP_NS]: { type: 'file-transfer-complete', payload: { id, totalChunks, timestamp: Date.now() } } },
      type: 'pcs',
      to: fromUUID
    });
    log(`Finished streaming file ${meta.name} → ${fromUUID}`);
  }

  // async function respondToFileRequest(fromUUID, payload) {
  //   const { id } = payload;
  //   const meta = files[id];
  //   if (!meta || !meta.file) {
  //     // tell requester file not found
  //     postToIframe({
  //       sendData: { [APP_NS]: { type: 'file-not-found', payload: { id } } },
  //       type: 'pcs',
  //       to: fromUUID
  //     });
  //     log('Requested file not found locally:', id);
  //     return;
  //   }

  //   const file = meta.file;
  //   const totalChunks = Math.ceil(file.size / FILE_CHUNK_BYTES);
  //   log(`Streaming file ${meta.name} to ${fromUUID} in ${totalChunks} chunks`);

  //   // send initial meta so receiver knows total / filename
  //   postToIframe({
  //     sendData: { [APP_NS]: { type: 'file-meta-announce', payload: { id, name: meta.name, size: meta.size, folderPath: meta.folderPath || '', totalChunks } } },
  //     type: 'pcs',
  //     to: fromUUID
  //   });

  //   // stream chunks sequentially
  //   for (let i = 0; i < totalChunks; i++) {
  //     const start = i * FILE_CHUNK_BYTES;
  //     const end = Math.min(file.size, start + FILE_CHUNK_BYTES);
  //     const blobSlice = file.slice(start, end);
  //     try {
  //       const buffer = await readBlobAsArrayBuffer(blobSlice);
  //       await sendChunkToPeer(fromUUID, id, i, totalChunks, buffer);
  //     } catch (err) {
  //       log('Error reading/sending chunk', i, err);
  //       // inform receiver of failure and abort
  //       postToIframe({
  //         sendData: { [APP_NS]: { type: 'file-transfer-error', payload: { id, message: err.message || 'chunk-read-error' } } },
  //         type: 'pcs',
  //         to: fromUUID
  //       });
  //       return;
  //     }
  //     // small delay to avoid exhausting the datachannel
  //     await sleep(CHUNK_SEND_DELAY);
  //   }

  //   // finalise
  //   postToIframe({
  //     sendData: { [APP_NS]: { type: 'file-transfer-complete', payload: { id, totalChunks, timestamp: Date.now() } } },
  //     type: 'pcs',
  //     to: fromUUID
  //   });
  //   log(`Finished streaming file ${meta.name} → ${fromUUID}`);
  // }

  function sendChunkRaw(targetUUID, id, index, total, arrayBuffer) {
    // Use base64 fallback as before (structured clone transferables might be blocked)
    const b64 = arrayBufferToBase64(arrayBuffer);
    const msg = {
      sendData: { [APP_NS]: { type: 'file-chunk', payload: { id, index, total, isBase64: true, data: b64, size: arrayBuffer.byteLength } } },
      type: 'pcs',
      to: targetUUID
    };
    postToIframe(msg);
  }

  function waitForChunkAck(id, index, timeoutMs = CHUNK_ACK_TIMEOUT) {
    const key = `${id}:${index}`;
    return new Promise((resolve, reject) => {
      // if already acked, resolve immediately
      if (outgoingFiles[id] && outgoingFiles[id].acks && outgoingFiles[id].acks[index]) return resolve();

      // create resolver
      outgoingFiles[id] = outgoingFiles[id] || {};
      outgoingFiles[id].resolvers = outgoingFiles[id].resolvers || {};
      let called = false;
      outgoingFiles[id].resolvers[key] = () => {
        if (called) return;
        called = true;
        clearTimeout(timer);
        delete outgoingFiles[id].resolvers[key];
        resolve();
      };

      const timer = setTimeout(() => {
        if (called) return;
        called = true;
        delete outgoingFiles[id].resolvers[key];
        reject(new Error('ack-timeout'));
      }, timeoutMs);
    });
  }

  async function sendChunkWithRetry(targetUUID, id, index, total, arrayBuffer) {
    outgoingFiles[id] = outgoingFiles[id] || { acks: {}, retries: {}, resolvers: {} };
    const retries = outgoingFiles[id].retries;
    retries[index] = retries[index] || 0;

    while (retries[index] <= CHUNK_MAX_RETRIES) {
      // if ack already received, break
      if (outgoingFiles[id].acks && outgoingFiles[id].acks[index]) return;

      // send
      sendChunkRaw(targetUUID, id, index, total, arrayBuffer);
      try {
        await waitForChunkAck(id, index, CHUNK_ACK_TIMEOUT);
        // ack received
        outgoingFiles[id].acks[index] = true;
        return;
      } catch (err) {
        // timeout -> retry
        retries[index] = (retries[index] || 0) + 1;
        log(`Retry ${retries[index]} for chunk ${index} of ${id}`);
        if (retries[index] > CHUNK_MAX_RETRIES) break;
        // short backoff
        await sleep(200 + 200 * retries[index]);
      }
    }

    throw new Error(`failed-to-get-ack-for-chunk-${index}`);
  }

  // Try to post buffer directly; fallback to base64 if structured clone fails.
  async function sendChunkToPeer(targetUUID, id, index, total, arrayBuffer) {
    const payload = { id, index, total, isBase64: false, size: arrayBuffer.byteLength };

    const msg = {
      sendData: { [APP_NS]: { type: "file-chunk", payload } },
      type: "pcs",
      to: targetUUID,
      buffer: arrayBuffer // include for easier debug
    };

    try {
      const b64 = arrayBufferToBase64(arrayBuffer);
      postToIframe({
        sendData: { [APP_NS]: { type: 'file-chunk', payload: { id, index, total, isBase64: true, data: b64 } } },
        type: 'pcs',
        to: targetUUID
      });

      // ✅ Pass arrayBuffer as transferable
      //postToIframe(msg, [arrayBuffer]);
    } catch (err) {
      console.warn("Transferable send failed, falling back to base64", err);
      const b64 = arrayBufferToBase64(arrayBuffer);
      const fallbackMsg = {
        sendData: {
          [APP_NS]: {
            type: "file-chunk",
            payload: { ...payload, isBase64: true, data: b64 },
          },
        },
        type: "pcs",
        to: targetUUID,
      };
      postToIframe(fallbackMsg);
    }
  }

  // Below: helper functions and the extra cases you need to add to handleDataReceived
  async function handleIncomingFileMeta(payload, from) {
    const { id, name, size, folderPath, totalChunks } = payload;
    incomingFiles[id] = incomingFiles[id] || { chunks: {}, totalChunks: totalChunks || null, receivedCount: 0, meta: { name, size, folderPath, uploadedBy: from } };
    incomingFiles[id].meta.name = name;
    incomingFiles[id].meta.size = size;
    incomingFiles[id].meta.folderPath = folderPath;
    incomingFiles[id].meta.uploadedBy = from;
    files[id] = files[id] || {};
    files[id].name = name;
    files[id].size = size;
    files[id].folderPath = folderPath;
    files[id].uploadedBy = from;
    files[id].status = 'transferring';
    createFileProgressUI(id, name); // ensure progress bar present
    log(`Receiving file meta: ${id} ${folderPath}/${name} (${formatBytes(size)})`);
  }

  // async function handleIncomingChunk(payload, rawEvent = null) {
  //   const { id, index, total, isBase64 } = payload;

  //   // --- ensure entry exists ---
  //   let entry = incomingFiles[id];
  //   if (!entry) {
  //     entry = incomingFiles[id] = {
  //       chunks: {},
  //       totalChunks: total || 0,
  //       receivedChunks: 0,
  //       bytesReceived: 0,
  //       size: (payload.size || total * CHUNK_SIZE || 0),
  //       startedAt: Date.now(),
  //       meta: {},
  //     };
  //   }

  //   let buffer = null;

  //   // --- normalize buffer sources ---
  //   if (rawEvent?.data?.buffer instanceof ArrayBuffer) {
  //     buffer = rawEvent.data.buffer;
  //   } else if (isBase64 && payload.data) {
  //     buffer = base64ToArrayBuffer(payload.data);
  //   } else if (payload.buffer instanceof ArrayBuffer) {
  //     buffer = payload.buffer;
  //   } else if (payload.data instanceof ArrayBuffer) {
  //     buffer = payload.data;
  //   }

  //   if (!buffer) {
  //     console.warn("⚠️ Failed to normalize buffer", payload);
  //     return;
  //   }

  //   // --- store chunk ---
  //   entry.chunks[index] = buffer;
  //   entry.totalChunks = total || entry.totalChunks;

  //   log(`Chunk - ${index + 1}/${entry.totalChunks} received for ${id}`);
  //   // --- calculate transfer stats ---
  //   const percent = (index / total) * 100;
  //   // --- update UI ---
  //   updateFileProgressUI(id, percent);

  //   if (entry.receivedChunks >= entry.totalChunks) {
  //     finalizeIncomingFile(id);
  //   }
  // }

  async function handleIncomingChunk(payload, rawEvent = null) {
    const { id, index, total, isBase64, size, uploadedBy } = payload;

    // --- ensure entry exists ---
    let entry = incomingFiles[id];
    if (!entry) {
      entry = incomingFiles[id] = {
        chunks: {},
        totalChunks: total || 0,
        receivedChunks: 0,
        bytesReceived: 0,
        uploadedBy: localUUID,
        size: (size || total * CHUNK_SIZE || 0),
        startedAt: Date.now(),
        meta: {},
      };
    }

    let buffer = null;
    if (rawEvent?.data?.buffer instanceof ArrayBuffer) {
      buffer = rawEvent.data.buffer;
    } else if (isBase64 && payload.data) {
      buffer = base64ToArrayBuffer(payload.data);
    } else if (payload.buffer instanceof ArrayBuffer) {
      buffer = payload.buffer;
    } else if (payload.data instanceof ArrayBuffer) {
      buffer = payload.data;
    }

    if (!buffer) {
      console.warn("⚠️ Failed to normalize buffer", payload);
      return;
    }

    // Avoid duplicate storing if chunk already arrived
    if (!entry.chunks[index]) {
      entry.chunks[index] = buffer;
      entry.receivedChunks = Object.keys(entry.chunks).length;
      entry.bytesReceived += buffer.byteLength;
    } else {
      // duplicate chunk; ignore but still ack to sender
      log(`Duplicate chunk ${index} for ${id} ignored`);
    }

    entry.totalChunks = total || entry.totalChunks;
    createFileProgressUI(id, id);

    // send ack back to the original uploader (if known)
    //const uploader = payload.uploadedBy;
    if (payload.uploadedBy != localUUID) {
      postToIframe({
        sendData: { [APP_NS]: { type: 'chunk-ack', payload: { id, index } } },
        type: 'pcs',
        to: payload.uploadedBy
      });
    }
    console.log("uploader:", payload.uploadedBy, "should not be", localUUID);

    log(`Chunk ${index + 1}/${entry.totalChunks} received for ${id}`);

    // compute stats for UI (you already have this in your code; keep it)
    //   // --- calculate transfer stats ---
    const percent = (index / total) * 100;
    //   // --- update UI ---
    updateFileProgressUI(id, percent);

    // When the receiver thinks it's complete, call finalizeIncomingFile (which may request-missing)
    if (entry.receivedChunks >= entry.totalChunks) {
      finalizeIncomingFile(id);
    }
  }

  // async function finalizeIncomingFile(id) {
  //   const entry = incomingFiles[id];
  //   if (!entry) return;
  //   const { chunks, totalChunks, meta } = entry;
  //   // ensure we have all parts
  //   if (totalChunks && Object.keys(chunks).length !== totalChunks) {
  //     log(`Cannot finalize ${id} — missing chunks (${Object.keys(chunks).length}/${totalChunks})`);
  //     if (entry.reject) entry.reject(new Error('missing-chunks'));
  //     return;
  //   }
  //   // assemble
  //   const buffers = [];
  //   for (let i = 0; i < totalChunks; i++) {
  //     const c = chunks[i];
  //     if (!c) {
  //       log('Missing chunk at index', i);
  //       if (entry.reject) entry.reject(new Error('missing-chunk-' + i));
  //       return;
  //     }
  //     // ensure ArrayBuffer (if view passed accidentally)
  //     buffers.push(c instanceof ArrayBuffer ? c : (ArrayBuffer.isView(c) ? c.buffer : c));
  //   }

  //   const blob = new Blob(buffers);
  //   // rename to RPXL - folder - sub - filename
  //   const safeFolder = (meta.folderPath || '').replace(/\//g, ' - ');
  //   const downloadName = `RPXL${safeFolder ? ' - ' + safeFolder : ''} - ${meta.name}`;
  //   triggerBrowserDownload(blob, downloadName);
  //   // mark status
  //   files[id] = files[id] || {};
  //   files[id].status = 'downloaded';
  //   log(`Saved file: ${downloadName}`);
  //   if (entry.resolve) entry.resolve();
  //   // cleanup
  //   delete incomingFiles[id];
  //   // kick queue processing in case there are more queued
  //   processDownloadQueue();
  // }

  async function finalizeIncomingFile(id) {
    const entry = incomingFiles[id];
    if (!entry) return;
    const { chunks, totalChunks, meta } = entry;

    const receivedCount = Object.keys(chunks).length;
    if (totalChunks && receivedCount !== totalChunks) {
      // determine missing indices
      const missing = [];
      for (let i = 0; i < totalChunks; i++) if (!chunks[i]) missing.push(i);

      log(`Missing chunks for ${id}: ${missing.length}/${totalChunks}`, missing.slice(0, 20));
      // Ask uploader to re-send missing chunks
      const uploader = entry.meta.uploadedBy || null;
      if (uploader && missing.length) {
        postToIframe({
          sendData: { [APP_NS]: { type: 'request-missing', payload: { id, missing } } },
          type: 'pcs',
          to: uploader
        });
        // Leave entry in incomingFiles — more chunks may come
        return;
      } else {
        // no uploader info — fail
        if (entry.reject) entry.reject(new Error('missing-chunks'));
        return;
      }
    }

    // assemble and download as before
    const buffers = [];
    for (let i = 0; i < totalChunks; i++) {
      const c = chunks[i];
      if (!c) {
        log('Missing chunk at index', i);
        if (entry.reject) entry.reject(new Error('missing-chunk-' + i));
        return;
      }
      buffers.push(c instanceof ArrayBuffer ? c : (ArrayBuffer.isView(c) ? c.buffer : c));
    }

    const blob = new Blob(buffers);
    const safeFolder = (meta.folderPath || '').replace(/\//g, ' - ');
    const downloadName = `RPXL${safeFolder ? ' - ' + safeFolder : ''} - ${meta.name}`;
    triggerBrowserDownload(blob, downloadName);
    files[id] = files[id] || {};
    files[id].status = 'downloaded';
    log(`Saved file: ${downloadName}`);
    if (entry.resolve) entry.resolve();
    delete incomingFiles[id];
    processDownloadQueue();
  }


  //show bytes nicely
  function formatBytes(bytes) {
    if (bytes < 1024) return `${bytes} B`;
    if (bytes < 1024 * 1024) return `${(bytes / 1024).toFixed(1)} KB`;
    if (bytes < 1024 * 1024 * 1024) return `${(bytes / 1024 / 1024).toFixed(1)} MB`;
    return `${(bytes / 1024 / 1024 / 1024).toFixed(1)} GB`;
  }
  // convert base64 -> ArrayBuffer
  function base64ToArrayBuffer(base64) {
    const binary_string = atob(base64);
    const len = binary_string.length;
    const bytes = new Uint8Array(len);
    for (let i = 0; i < len; i++) bytes[i] = binary_string.charCodeAt(i);
    return bytes.buffer;
  }
  function arrayBufferToBase64(buffer) {
    let binary = '';
    const bytes = new Uint8Array(buffer);
    const chunkSize = 0x8000;
    for (let i = 0; i < bytes.length; i += chunkSize) {
      binary += String.fromCharCode.apply(null, bytes.subarray(i, i + chunkSize));
    }
    return btoa(binary);
  }

  // read Blob slice as ArrayBuffer
  function readBlobAsArrayBuffer(blob) {
    return new Promise((res, rej) => {
      const fr = new FileReader();
      fr.onload = () => res(fr.result);
      fr.onerror = rej;
      fr.readAsArrayBuffer(blob);
    });
  }

  // do actual browser download
  function triggerBrowserDownload(blob, filename) {
    const url = URL.createObjectURL(blob);
    const a = document.createElement('a');
    a.href = url;
    a.download = filename;
    document.body.appendChild(a);
    a.click();
    a.remove();
    setTimeout(() => URL.revokeObjectURL(url), 60_000);
  }

</script>